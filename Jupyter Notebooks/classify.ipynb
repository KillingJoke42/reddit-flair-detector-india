{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classify.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1apiE18fnJbr",
        "colab_type": "text"
      },
      "source": [
        "**MIDAS SCREENING TASK: FLAIR DETECTOR-CLASSIFIER CODE**<br>\n",
        "Code Segment contains attempts at building a classifier: we have taken 4 different ML classifier types, namely:\n",
        "\n",
        "1) Native Baye's Classifier <br>\n",
        "2) Logistic Regression <br>\n",
        "3) Random Forrest <br>\n",
        "4) Linear SVM <br>\n",
        "\n",
        "This code highlights both the classifier elements and the training of the classifier\n",
        "\n",
        "Final Accuracy Metrics: (Testing on 1722 samples from new)<br>\n",
        "*On Title*<br>\n",
        "NB: 53%<br>\n",
        "LogRegression: 49%<br>\n",
        "RandomForrest: 46%<br>\n",
        "LinearSVM: 49%<br>\n",
        "\n",
        "*On Comments*<br>\n",
        "NB: 26%<br>\n",
        "LogRegression: 22%<br>\n",
        "RandomForrest: 24%<br>\n",
        "LinearSVM: 22%<br>\n",
        "\n",
        "*On URL*<br>\n",
        "NB: 10%<br>\n",
        "LogRegression: 8%<br>\n",
        "RandomForrest: 7%<br>\n",
        "LinearSVM: 8%<br>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGgtRxBnowCM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "classify.py: get flair predictions for reddit posts. \n",
        "Author: Anant Raina\n",
        "Date: 8th April, 2020\n",
        "Last Commit: 24th April, 2020\n",
        "Trains the models over 750 hot posts from r/India and also gets the prediction using a given classifier\n",
        "\"\"\"\n",
        "\n",
        "#CSV to open dataset that is of the .csv format\n",
        "from csv import reader\n",
        "\n",
        "# Numpy dependancy for dataset management within python\n",
        "import numpy as np\n",
        "\n",
        "# Machine Leanring Dependancies from sklearn\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# Joblib to save the Machine Learning Model\n",
        "import joblib\n",
        "\n",
        "# re and nltk are NLP libraries that are required to cleanup the dataset we make\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2C0okhNpxmt",
        "colab_type": "text"
      },
      "source": [
        "**REMOVING ALL UNWANTED SYMBOLS AND EXPRESSIONS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SwTSMGRLpqhh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# -------CODE BEGINS--------\n",
        "\n",
        "#Get all the symbols that are undesired and unwanted in the training/testing set\n",
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+,_\\\"]')\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "# Remove HTML tags if any from the samples\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)\n",
        "\n",
        "# Perform removal of unwanted symbols from the samples\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = remove_tags(text)\n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text)\n",
        "    text = BAD_SYMBOLS_RE.sub('', text)\n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuaDE0UIp-GU",
        "colab_type": "text"
      },
      "source": [
        "**PREPARE THE TRAINING SET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OlWWsNXp3zX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prepare a training set: Outputs train_data, labels as strings, labels as integers, and the mapping between the two\n",
        "def prepare_train_data():\n",
        "\tX_train = list()\n",
        "\ty_train_text = list()\n",
        "\n",
        "\tget_metric = dict()\n",
        "\n",
        "\twith open('hot/flair_dataset.csv') as csv_file:\n",
        "\t\tcsv_reader = reader(csv_file, delimiter=',', quotechar='\"')\n",
        "\t\tfor row in csv_reader:\n",
        "\t\t\tif row[1] != '':\n",
        "\t\t\t\tif row[1] in get_metric.keys():\n",
        "\t\t\t\t\tget_metric[row[1]] += 1\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\tget_metric[row[1]] = 1\n",
        "\t\t\t\tX_train.append(preprocess_text(row[0]))\n",
        "\t\t\t\ty_train_text.append(row[1])\n",
        "\n",
        "\tX_train = np.array(X_train)\n",
        "\ty_train_text = np.array([[flair] for flair in y_train_text])\n",
        "\ty_train = dict()\n",
        "\ty_train_vectored = list()\n",
        "\tcountVector = 0\n",
        "\tfor i in range(y_train_text.shape[0]):\n",
        "\t\tlabel = y_train_text[i][0]\n",
        "\t\tif label not in y_train.keys():\n",
        "\t\t\ty_train[label] = countVector\n",
        "\t\t\ty_train_vectored.append(countVector)\n",
        "\t\t\tcountVector += 1\n",
        "\t\telse:\n",
        "\t\t\ty_train_vectored.append(y_train[label])\n",
        "\ty_train_vectored = np.array(y_train_vectored)\n",
        "\treturn X_train, y_train_text, y_train_vectored, y_train"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2QyoqaNqXUQ",
        "colab_type": "text"
      },
      "source": [
        "**OBTAIN TRAINING SET**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbOQuu69qb2I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, y_train_text, y_train_vectored, y_train = prepare_train_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eydM0hm8qhwj",
        "colab_type": "text"
      },
      "source": [
        "**BEGIN TRAINING OF ML MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oYf5PJIqhOQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Train ML models on the train data. Four types of models were chosen for testing:\n",
        "# 1) Native Baye's Classifier\n",
        "# 2) Random Forrest Model\n",
        "# 3) Linear Support Vector Machine\n",
        "# 4) Logistic Regression\n",
        "def ml_train(model_type):\n",
        "\t\n",
        "\tif model_type == \"baye\":\n",
        "\t\tprint(y_train)\n",
        "\t\tclassifier = Pipeline([\n",
        "\t\t\t('vectorizer', CountVectorizer()),\n",
        "\t\t\t('tfidf', TfidfTransformer()),\n",
        "\t\t\t('clf', MultinomialNB())])\n",
        "\t\tclassifier.fit(X_train, y_train_vectored)\n",
        "\t\tfilename = 'native_baye.sav'\n",
        "\t\tjoblib.dump(classifier, filename)\n",
        "\n",
        "\telif model_type == \"sgd\":\n",
        "\t\tprint(y_train)\n",
        "\t\tclassifier = Pipeline([\n",
        "\t\t\t('vectorizer', CountVectorizer()),\n",
        "\t\t\t('tfidf', TfidfTransformer()),\n",
        "\t\t\t('clf', SGDClassifier(loss='hinge', penalty='l2',alpha=1e-3, random_state=42, max_iter=5, tol=None))])\n",
        "\t\tclassifier.fit(X_train, y_train_vectored)\n",
        "\t\tfilename = 'sgd.sav'\n",
        "\t\tjoblib.dump(classifier, filename)\n",
        "\n",
        "\telif model_type == \"regression\":\n",
        "\t\tprint(y_train)\n",
        "\t\tclassifier = Pipeline([\n",
        "\t\t\t('vectorizer', CountVectorizer()),\n",
        "\t\t\t('tfidf', TfidfTransformer()),\n",
        "\t\t\t('clf', LogisticRegression(n_jobs=1, C=1e5, max_iter=10000))])\n",
        "\t\tclassifier.fit(X_train, y_train_vectored)\n",
        "\t\tfilename = 'regression.sav'\n",
        "\t\tjoblib.dump(classifier, filename)\n",
        "\n",
        "\telif model_type == \"random_forrest\":\n",
        "\t\tprint(y_train)\n",
        "\t\tclassifier = Pipeline([\n",
        "\t\t\t('vectorizer', CountVectorizer()),\n",
        "\t\t\t('tfidf', TfidfTransformer()),\n",
        "\t\t\t('clf', RandomForestClassifier(n_estimators = 1000, random_state = 42))])\n",
        "\t\tclassifier.fit(X_train, y_train_vectored)\n",
        "\t\tfilename = 'random_forrest.sav'\n",
        "\t\tjoblib.dump(classifier, filename)\n",
        "\n",
        "\telif model_type == \"all\":\n",
        "\t\tml_train(\"baye\")\n",
        "\t\tml_train(\"sgd\")\n",
        "\t\tml_train(\"regression\")\n",
        "\t\tml_train(\"random_forrest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwQVA5HhqxRX",
        "colab_type": "text"
      },
      "source": [
        "**THE CLASSIFIER: INPUT THE MODELFILE AND TEXT AND GET THE PREDICTION AS OUTPUT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wKJD2Mwqw-0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get prediction over a test string. Requires a modelfile as input (.sav format) and the test string\n",
        "def classify(classifier, text):\n",
        "\tX_test = np.array([preprocess_text(text)])\n",
        "\tpredicted = classifier.predict(X_test)\n",
        "\treturn predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fO0hfrfCrB1j",
        "colab_type": "text"
      },
      "source": [
        "**TRAIN MODEL AS PER REQUIREMENT: DEFAULT IS ALL MODELS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmFJ-gwtrIIL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ml_train(\"all\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}